{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c68c36e",
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n",
      "<class 'xgboost.sklearn.XGBRegressor'>\n"
     ]
    }
   ],
   "source": [
    "%debug\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, scrolledtext\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "try:\n",
    "    with open('best_xgb_model.pkl', 'rb') as model_file:\n",
    "        model = pickle.load(model_file)\n",
    "        print(\"Model loaded successfully.\")\n",
    "        #print(\"Model attributes:\", model.get_params())  # Print model attributes for debugging\n",
    "        print(type(model))  # Print model for debugging\n",
    "except (FileNotFoundError, EOFError, pickle.UnpicklingError):\n",
    "    # Handle file not found or unpickling errors\n",
    "    print(\"Error loading XGBoost model.\")\n",
    "\n",
    "# Load MinMaxScaler\n",
    "with open('min_max_scaler.pkl', 'rb') as scaler_file:\n",
    "    scaler = pickle.load(scaler_file)\n",
    "\n",
    "# Load LabelEncoder for 'brand'\n",
    "with open('label_encoder_brand.pkl', 'rb') as label_encoder_file:\n",
    "    label_encoder_brand = pickle.load(label_encoder_file)\n",
    "\n",
    "# Check if the model is fitted\n",
    "if not hasattr(model, '_Booster') or model._Booster is None:\n",
    "    raise NotFittedError(\"The XGBoost model needs to be fitted or loaded before making predictions.\")\n",
    "\n",
    "# Function to perform feature engineering and scaling\n",
    "def perform_feature_engineering_and_scaling(df):\n",
    "    # Drop unnecessary columns\n",
    "    df = df.drop(['seller', 'offerType', 'model', 'name', 'dateCrawled', 'lastSeen', 'dateCreated', 'postalCode'], axis=1)\n",
    "    \n",
    "    # Creating dummies\n",
    "    df = pd.get_dummies(df, columns=['abtest','vehicleType', 'fuelType', 'gearbox', 'notRepairedDamage'], drop_first=True)\n",
    "\n",
    "    # Ensure that dummy columns are consistent with the training data\n",
    "    dummy_columns_train = set(['abtest_test', 'vehicleType_cabrio', 'vehicleType_coupe', 'vehicleType_limousine', 'vehicleType_others',\n",
    "                                'vehicleType_small car', 'vehicleType_station wagon', 'vehicleType_suv', 'fuelType_diesel',\n",
    "                                'fuelType_electro', 'fuelType_hybrid', 'fuelType_lpg', 'fuelType_other', 'fuelType_petrol',\n",
    "                                'gearbox_manual', 'notRepairedDamage_yes'])\n",
    "\n",
    "    dummy_columns_current = set(df.columns)\n",
    "    missing_dummy_columns = dummy_columns_train - dummy_columns_current\n",
    "    for column in missing_dummy_columns:\n",
    "        df[column] = 0\n",
    "\n",
    "    extra_dummy_columns = dummy_columns_current - dummy_columns_train\n",
    "    df = df.drop(extra_dummy_columns, axis=1)\n",
    "    \n",
    "    # Label encoding for the 'brand' column\n",
    "    if 'brand' in df.columns:\n",
    "        df['brand_encoded'] = label_encoder_brand.transform(df['brand'])\n",
    "        # Dropping brand column\n",
    "        df = df.drop('brand', axis=1)\n",
    "    else:\n",
    "        # If 'brand' column is not present, you may need to handle this case based on your requirements\n",
    "        # For now, let's assume the 'brand' column is missing and set 'brand_encoded' to a default value\n",
    "        df['brand_encoded'] = 0  # You may need to choose a suitable default value\n",
    "\n",
    "#     # Convert 'yearOfRegistration' to numeric\n",
    "#     df['yearOfRegistration'] = pd.to_numeric(df['yearOfRegistration'], errors='coerce')\n",
    "\n",
    "    # Calculate the age of the vehicle\n",
    "    df['yearOfRegistration'] = df['yearOfRegistration'].apply(lambda x: 2023 - x)\n",
    "\n",
    "    # Rename column name from 'yearOfRegistration' to 'YearsFromRegistration'\n",
    "    df.rename(columns={ 'yearOfRegistration':'YearsFromRegistration'}, inplace=True)\n",
    "\n",
    "#     # Convert 'yearOfRegistration' to numeric\n",
    "#     df['monthOfRegistration'] = pd.to_numeric(df['monthOfRegistration'], errors='coerce')\n",
    "\n",
    "#     # Convert 'powerPS' to numeric\n",
    "#     df['powerPS'] = pd.to_numeric(df['powerPS'], errors='coerce')\n",
    "\n",
    "#     # Convert 'kilometer' to numeric\n",
    "#     df['kilometer'] = pd.to_numeric(df['kilometer'], errors='coerce')\n",
    "\n",
    "    # Perform binning for \"monthOfRegistration\" column\n",
    "    bins = [0, 3, 6, 9, 12]\n",
    "    labels = [\"Q1\", \"Q2\", \"Q3\", \"Q4\"]\n",
    "    df['monthOfRegistration'] = pd.cut(df['monthOfRegistration'], bins=bins, labels=labels)\n",
    "    df = pd.get_dummies(df, columns=['monthOfRegistration'], drop_first=True)\n",
    "\n",
    "    # Scale the specified columns\n",
    "    columns_to_scale = ['YearsFromRegistration', 'powerPS', 'kilometer', 'brand_encoded']\n",
    "    df[columns_to_scale] = scaler.transform(df[columns_to_scale])\n",
    "\n",
    "    return df\n",
    "\n",
    "# Function to predict price\n",
    "def predict_price(features):\n",
    "    # Load the features into a DataFrame\n",
    "    input_data = pd.DataFrame(features, index=[0])\n",
    "\n",
    "    # Perform feature engineering and scaling\n",
    "    input_data = perform_feature_engineering_and_scaling(input_data)\n",
    "    print(input_data)\n",
    "    # Predict the price using the pre-trained model\n",
    "    predicted_price = model.predict(input_data)\n",
    "\n",
    "    return predicted_price[0]\n",
    "\n",
    "# Tkinter GUI\n",
    "class CarPricePredictionApp:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Car Price Prediction App\")\n",
    "\n",
    "        # Create a scrolled text widget for displaying the output\n",
    "        self.output_text = scrolledtext.ScrolledText(root, width=50, height=10)\n",
    "        self.output_text.grid(row=0, column=2, rowspan=20, padx=10, pady=10, sticky=\"nsew\")\n",
    "\n",
    "        # Create and place input labels and entry widgets\n",
    "        self.input_entries = {}\n",
    "        input_features = ['dateCrawled', 'name', 'seller', 'offerType', 'abtest', 'vehicleType', 'yearOfRegistration',\n",
    "                           'gearbox', 'powerPS', 'model', 'kilometer', 'monthOfRegistration', 'fuelType', 'brand',\n",
    "                           'notRepairedDamage', 'dateCreated', 'postalCode', 'lastSeen']\n",
    "\n",
    "        for feature in input_features:\n",
    "            label = ttk.Label(root, text=feature)\n",
    "            label.grid(row=input_features.index(feature), column=0, padx=10, pady=10, sticky=tk.W)\n",
    "\n",
    "            entry = ttk.Entry(root)\n",
    "            entry.grid(row=input_features.index(feature), column=1, padx=10, pady=10, sticky=tk.W)\n",
    "            self.input_entries[feature] = entry\n",
    "\n",
    "        # Create and place the Predict button\n",
    "        predict_button = ttk.Button(root, text=\"Predict Price\", command=self.predict_price)\n",
    "        predict_button.grid(row=len(input_features), column=0, columnspan=2, pady=20)\n",
    "\n",
    "    def predict_price(self):\n",
    "        # Get user inputs\n",
    "        features = {feature: entry.get() for feature, entry in self.input_entries.items()}\n",
    "\n",
    "        # Convert user inputs to appropriate data types\n",
    "        features['yearOfRegistration'] = pd.to_numeric(features['yearOfRegistration'], errors='coerce')\n",
    "        features['powerPS'] = pd.to_numeric(features['powerPS'], errors='coerce')\n",
    "        features['kilometer'] = pd.to_numeric(features['kilometer'], errors='coerce')\n",
    "\n",
    "        # Perform prediction\n",
    "        predicted_price = predict_price(features)\n",
    "\n",
    "        # Display the predicted price\n",
    "        self.output_text.delete(1.0, tk.END)  # Clear previous text\n",
    "        self.output_text.insert(tk.END, f\"Predicted Price: {predicted_price:.2f} USD\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = CarPricePredictionApp(root)\n",
    "\n",
    "    # Configure the grid to expand with the window\n",
    "    root.columnconfigure(2, weight=1)\n",
    "    root.rowconfigure(0, weight=1)\n",
    "\n",
    "    root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fcf9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import ttk, scrolledtext\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.exceptions import NotFittedError\n",
    "\n",
    "def load_model():\n",
    "    try:\n",
    "        with open('best_xgb_model.pkl', 'rb') as model_file:\n",
    "            model = pickle.load(model_file)\n",
    "            print(\"Model loaded successfully.\")\n",
    "        return model\n",
    "    except (FileNotFoundError, EOFError, pickle.UnpicklingError):\n",
    "        print(\"Error loading XGBoost model.\")\n",
    "        return None\n",
    "\n",
    "def load_scaler():\n",
    "    with open('min_max_scaler.pkl', 'rb') as scaler_file:\n",
    "        scaler = pickle.load(scaler_file)\n",
    "    return scaler\n",
    "\n",
    "def load_label_encoder():\n",
    "    with open('label_encoder_brand.pkl', 'rb') as label_encoder_file:\n",
    "        label_encoder = pickle.load(label_encoder_file)\n",
    "    return label_encoder\n",
    "\n",
    "def check_model_fitted(model):\n",
    "    if not hasattr(model, '_Booster') or model._Booster is None:\n",
    "        raise NotFittedError(\"The XGBoost model needs to be fitted or loaded before making predictions.\")\n",
    "\n",
    "def perform_feature_engineering_and_scaling(df, label_encoder_brand, scaler):\n",
    "    # Drop unnecessary columns\n",
    "    df = df.drop(['seller', 'offerType', 'model', 'name', 'dateCrawled', 'lastSeen', 'dateCreated', 'postalCode'], axis=1)\n",
    "    \n",
    "    # Creating dummies\n",
    "    df = pd.get_dummies(df, columns=['abtest','vehicleType', 'fuelType', 'gearbox', 'notRepairedDamage'], drop_first=True)\n",
    "\n",
    "    # Ensure that dummy columns are consistent with the training data\n",
    "    dummy_columns_train = set(['abtest_test', 'vehicleType_cabrio', 'vehicleType_coupe', 'vehicleType_limousine', 'vehicleType_others',\n",
    "                                'vehicleType_small car', 'vehicleType_station wagon', 'vehicleType_suv', 'fuelType_diesel',\n",
    "                                'fuelType_electro', 'fuelType_hybrid', 'fuelType_lpg', 'fuelType_other', 'fuelType_petrol',\n",
    "                                'gearbox_manual', 'notRepairedDamage_yes'])\n",
    "\n",
    "    dummy_columns_current = set(df.columns)\n",
    "    missing_dummy_columns = dummy_columns_train - dummy_columns_current\n",
    "    for column in missing_dummy_columns:\n",
    "        df[column] = 0\n",
    "\n",
    "    extra_dummy_columns = dummy_columns_current - dummy_columns_train\n",
    "    df = df.drop(extra_dummy_columns, axis=1)\n",
    "    \n",
    "    # Label encoding for the 'brand' column\n",
    "    if 'brand' in df.columns:\n",
    "        df['brand_encoded'] = label_encoder_brand.transform(df['brand'])\n",
    "        # Dropping brand column\n",
    "        df = df.drop('brand', axis=1)\n",
    "    else:\n",
    "        # If 'brand' column is not present, you may need to handle this case based on your requirements\n",
    "        # For now, let's assume the 'brand' column is missing and set 'brand_encoded' to a default value\n",
    "        df['brand_encoded'] = 0  # You may need to choose a suitable default value\n",
    "\n",
    "    # Calculate the age of the vehicle\n",
    "    df['yearOfRegistration'] = df['yearOfRegistration'].apply(lambda x: 2023 - x)\n",
    "\n",
    "    # Rename column name from 'yearOfRegistration' to 'YearsFromRegistration'\n",
    "    df.rename(columns={ 'yearOfRegistration':'YearsFromRegistration'}, inplace=True)\n",
    "\n",
    "    # Perform binning for \"monthOfRegistration\" column\n",
    "    bins = [0, 3, 6, 9, 12]\n",
    "    labels = [\"Q1\", \"Q2\", \"Q3\", \"Q4\"]\n",
    "    df['monthOfRegistration'] = pd.cut(df['monthOfRegistration'], bins=bins, labels=labels)\n",
    "    df = pd.get_dummies(df, columns=['monthOfRegistration'], drop_first=True)\n",
    "\n",
    "    # Scale the specified columns\n",
    "    columns_to_scale = ['YearsFromRegistration', 'powerPS', 'kilometer', 'brand_encoded']\n",
    "    df[columns_to_scale] = scaler.transform(df[columns_to_scale])\n",
    "\n",
    "    return df\n",
    "\n",
    "def predict_price(model, input_data):\n",
    "    predicted_price = model.predict(input_data)\n",
    "    return predicted_price[0]\n",
    "\n",
    "def create_gui(root):\n",
    "    root.title(\"Car Price Prediction App\")\n",
    "\n",
    "    output_text = scrolledtext.ScrolledText(root, width=50, height=10)\n",
    "    output_text.grid(row=0, column=2, rowspan=20, padx=10, pady=10, sticky=\"nsew\")\n",
    "\n",
    "    input_entries = {}\n",
    "    input_features = ['dateCrawled', 'name', 'seller', 'offerType', 'abtest', 'vehicleType', 'yearOfRegistration',\n",
    "                       'gearbox', 'powerPS', 'model', 'kilometer', 'monthOfRegistration', 'fuelType', 'brand',\n",
    "                       'notRepairedDamage', 'dateCreated', 'postalCode', 'lastSeen']\n",
    "\n",
    "    for feature in input_features:\n",
    "        label = ttk.Label(root, text=feature)\n",
    "        label.grid(row=input_features.index(feature), column=0, padx=10, pady=10, sticky=tk.W)\n",
    "\n",
    "        entry = ttk.Entry(root)\n",
    "        entry.grid(row=input_features.index(feature), column=1, padx=10, pady=10, sticky=tk.W)\n",
    "        input_entries[feature] = entry\n",
    "\n",
    "    def predict_price_callback():\n",
    "        features = {feature: entry.get() for feature, entry in input_entries.items()}\n",
    "        features['yearOfRegistration'] = pd.to_numeric(features['yearOfRegistration'], errors='coerce')\n",
    "        features['powerPS'] = pd.to_numeric(features['powerPS'], errors='coerce')\n",
    "        features['kilometer'] = pd.to_numeric(features['kilometer'], errors='coerce')\n",
    "\n",
    "        model = load_model()\n",
    "        scaler = load_scaler()\n",
    "        label_encoder_brand = load_label_encoder()\n",
    "\n",
    "        check_model_fitted(model)\n",
    "\n",
    "        input_data = pd.DataFrame(features, index=[0])\n",
    "        input_data = perform_feature_engineering_and_scaling(input_data, label_encoder_brand, scaler)\n",
    "\n",
    "        try:\n",
    "            check_model_fitted(model)\n",
    "            predicted_price = predict_price(model, input_data)\n",
    "            output_text.delete(1.0, tk.END)\n",
    "            output_text.insert(tk.END, f\"Predicted Price: {predicted_price:.2f} USD\\n\")\n",
    "        except NotFittedError as e:\n",
    "            output_text.delete(1.0, tk.END)\n",
    "            output_text.insert(tk.END, f\"Error: {str(e)}\\n\")\n",
    "\n",
    "    predict_button = ttk.Button(root, text=\"Predict Price\", command=predict_price_callback)\n",
    "    predict_button.grid(row=len(input_features), column=0, columnspan=2, pady=20)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    create_gui(root)\n",
    "    root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
